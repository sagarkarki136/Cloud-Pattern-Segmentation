{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install segmentation-models --quiet\nimport tensorflow as tf\n\nimport keras\nimport keras.backend as K\nimport keras.callbacks as cbs\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os, shutil\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold, train_test_split","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/cloud-images-resized/train_384x576.csv')\ntrain['Image']=train['Image_Label'].map(lambda x: x.split(\"_\")[0])\ntrain['Label']=train['Image_Label'].map(lambda x: x.split(\"_\")[1])\ntrain2=pd.DataFrame({'Image':train['Image'][::4]})\ntrain2['e1']=train['EncodedPixels'][::4].values\ntrain2['e2']=train['EncodedPixels'][1::4].values\ntrain2['e3']=train['EncodedPixels'][2::4].values\ntrain2['e4']=train['EncodedPixels'][3::4].values\ntrain2.set_index('Image', drop=True, inplace=True)\ntrain2=train2.fillna('')\ntrain2[['d1','d2','d3','d4']]=(train2[['e1','e2','e3','e4']]!='').astype(int)\ntrain2.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                                                            e1  \\\nImage                                                            \n0011165.jpg  20056 257 20440 257 20824 257 21208 257 21592 ...   \n002be4f.jpg  17668 241 18051 242 18435 242 18819 242 19203 ...   \n0031ae9.jpg  579 190 963 190 1347 190 1731 190 2115 190 249...   \n0035239.jpg                                                      \n003994e.jpg  178332 27 178715 28 179089 2 179092 35 179470 ...   \n\n                                                            e2  \\\nImage                                                            \n0011165.jpg  102245 275 102629 275 103013 275 103397 275 10...   \n002be4f.jpg  100850 142 101234 142 101618 142 102002 142 10...   \n0031ae9.jpg  178 193 562 193 946 193 1330 193 1714 193 2098...   \n0035239.jpg  7684 127 8068 127 8452 127 8836 127 9220 127 9...   \n003994e.jpg                                                      \n\n                                                            e3  \\\nImage                                                            \n0011165.jpg                                                      \n002be4f.jpg                                                      \n0031ae9.jpg                                                      \n0035239.jpg  5267 104 5651 104 6035 104 6419 104 6803 104 7...   \n003994e.jpg  26639 114 27023 114 27407 114 27791 114 28175 ...   \n\n                                                            e4  d1  d2  d3  d4  \nImage                                                                           \n0011165.jpg                                                      1   1   0   0  \n002be4f.jpg  5074 96 5458 96 5842 96 6226 96 6610 96 6994 9...   1   1   0   1  \n0031ae9.jpg  49583 107 49967 107 50351 107 50735 107 51119 ...   1   1   0   1  \n0035239.jpg                                                      0   1   1   0  \n003994e.jpg  1924 133 2308 134 2692 134 3076 134 3460 134 3...   1   0   1   1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>e1</th>\n      <th>e2</th>\n      <th>e3</th>\n      <th>e4</th>\n      <th>d1</th>\n      <th>d2</th>\n      <th>d3</th>\n      <th>d4</th>\n    </tr>\n    <tr>\n      <th>Image</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0011165.jpg</th>\n      <td>20056 257 20440 257 20824 257 21208 257 21592 ...</td>\n      <td>102245 275 102629 275 103013 275 103397 275 10...</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>002be4f.jpg</th>\n      <td>17668 241 18051 242 18435 242 18819 242 19203 ...</td>\n      <td>100850 142 101234 142 101618 142 102002 142 10...</td>\n      <td></td>\n      <td>5074 96 5458 96 5842 96 6226 96 6610 96 6994 9...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0031ae9.jpg</th>\n      <td>579 190 963 190 1347 190 1731 190 2115 190 249...</td>\n      <td>178 193 562 193 946 193 1330 193 1714 193 2098...</td>\n      <td></td>\n      <td>49583 107 49967 107 50351 107 50735 107 51119 ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0035239.jpg</th>\n      <td></td>\n      <td>7684 127 8068 127 8452 127 8836 127 9220 127 9...</td>\n      <td>5267 104 5651 104 6035 104 6419 104 6803 104 7...</td>\n      <td></td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>003994e.jpg</th>\n      <td>178332 27 178715 28 179089 2 179092 35 179470 ...</td>\n      <td></td>\n      <td>26639 114 27023 114 27407 114 27791 114 28175 ...</td>\n      <td>1924 133 2308 134 2692 134 3076 134 3460 134 3...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle,shrink=1,shape=(2100,1400)):\n    rle=rle.split()\n    starts,lengths=[np.asarray(x,dtype=int) for (x) in(rle[::2],rle[1::2]) ]\n    starts-=1\n    ends=starts+lengths\n    mask=np.zeros(shape[0]*shape[1],dtype='uint8')\n    \n    for lo,hi in zip(starts,ends):\n        mask[lo:hi]=1\n        \n    return mask.reshape(shape).T[::shrink,::shrink]\n        ","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as albu\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","execution_count":4,"outputs":[{"output_type":"stream","text":"env: SM_FRAMEWORK=tf.keras\nSegmentation Models: using `tf.keras` framework.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self,list_ids,shrink1=1,shrink2=1,dim=(576,384),height= 352, width=544,\n                path='../input/cloud-images-resized/train_images_384x576/',\n                 flips=False, augment=False,batch_size=32,scale=1/128,sub=1,mode='train',shuffle=False):\n        self.shrink1=shrink1\n        self.shrink2=shrink2\n        self.mode=mode\n        self.path=path\n        self.dim=dim\n        self.augment=augment\n        self.height=height\n        self.width=width\n        self.list_ids=list_ids\n        self.batch_size=batch_size\n        self.flips=flips\n        self.scale=scale\n        self.sub=sub\n        self.shuffle=shuffle\n        self.on_epoch_end()\n        \n    def __len__(self):\n        ct= int(np.floor(len(self.list_ids)/(self.batch_size)))\n        if len(self.list_ids)>ct*self.batch_size:\n            ct+=1\n        return ct\n    \n    def __getitem__(self,index):\n        indexes=self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n        X,msk=self.__generate_data(indexes)\n#         print(X[1])\n        if self.augment : X,msk=self.__batch_aug(X,msk)\n        if (self.mode=='train')|(self.mode=='val'):\n            return X,msk\n        else : return X\n        \n    def __generate_data(self,indexes):\n        \n        lnn= len(indexes) ;ex=self.shrink1 ;ax =self.shrink2\n        X = np.empty((lnn,self.height, self.width,3),dtype=np.float32)\n        msk=np.empty((lnn,self.height,self.width,4),dtype=np.float32)\n        \n        for i in range(lnn):\n            img=cv2.imread(self.path+self.list_ids[indexes[i]])\n            hflips=False ; vflips=False\n            if(self.flips):\n                if np.random.uniform(0,1)>0.5 : hflips=True\n                if np.random.uniform(0,1)>0.5 : vflips=True\n            if hflips:\n                img=cv2.flip(img,1)\n            if vflips:\n                img=cv2.flip(img,0)\n            \n            ## shake augment\n            a=np.random.randint(0,self.dim[0]//ax//ex-self.width/ax+1)\n            \n            b=np.random.randint(0,self.dim[1]//ax//ex-self.height/ax+1)\n            \n            if (self.mode=='predict'):\n                a=(self.dim[0]//ex//ax-self.width//ax)//2\n                b=(self.dim[1]//ex//ax-self.height//ax)//2\n                \n            img=img[b*ax:self.height+b*ax,a*ax:self.width+a*ax]\n            X[i]=img*self.scale - self.sub\n            \n            \n            if (self.mode!='predict'):\n                \n                for j in range(1,5):\n                    rle=train2.loc[self.list_ids[indexes[i]],'e'+str(j)]\n                    mask=rle2mask(rle,shrink=ex*ax,shape=self.dim)\n                    if hflips:\n                        mask=np.flip(mask,axis=1)\n                    if vflips:\n                        mask=np.flip(mask,axis=0)\n                    msk[i,:,:,j-1]=mask[b:self.height//ax+b,a:self.width//ax+a]\n                    \n                    \n        return X,msk\n    \n    def on_epoch_end(self):\n        self.indexes=np.arange(int(len(self.list_ids)))\n        if self.shuffle: np.random.shuffle(self.indexes)\n            \n    def __random_transform(self, img,mask):\n        composition=albu.Compose([\n        albu.ShiftScaleRotate(scale_limit=0.1,rotate_limit=30,p=0.5)\n        ])\n        \n        composed=composition(image=img,mask=mask)\n#         print(composed['image'])\n        return composed['image'],composed['mask']\n        \n    def __batch_aug(self,img_batch,mask_batch):\n        for i in  range(img_batch.shape[0]):\n            img_batch[i],mask_batch[i]=self.__random_transform(img_batch[i],mask_batch[i])\n#         print(img_batch[1])\n        return img_batch, mask_batch\n                \n                \n                \n            \n                ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_gen=DataGenerator(train2.index,augment=True,shuffle=True)\n# X,msk=train_gen.__getitem__(3)\n# print(X.shape,msk.shape)\n# for i in range(5):\n#     fig,ax=plt.subplots(figsize=(20,20))\n#     ax.imshow(X[i])\n#     ax.imshow(msk[i])\n#     plt.show()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filters = [256, 128, 64, 32, 16]\nREDUCTION = 0; RED = 2**REDUCTION\nfilters = filters[:5-REDUCTION]\n\nBATCH_SIZE = 16\njaccard_loss = sm.losses.JaccardLoss() \n\nskf = KFold(n_splits=3, shuffle=True)#, random_state=RAND)\n# for k, (idxT0, idxV0) in enumerate( skf.split(train2) ):\ntrain_idx,val_idx=train_test_split(train2.index,test_size=0.1)\n# train_idx = train2.index[idxT0]\n# val_idx = train2.index[idxV0]\n\n# if k==0: idx_oof_0 = val_idx.copy()\n# elif k==1: idx_oof_1 = val_idx.copy()\n# elif k==2: idx_oof_2 = val_idx.copy()\n\n# print('#'*20)\n# print('### Fold',k,'###')\n# print('#'*20)\n\n#     if not DO_TRAIN: continue\n\ntrain_generator = DataGenerator(\n    train_idx, flips=True, augment=True, shuffle=True, shrink2=RED, batch_size=BATCH_SIZE,\n)\n\nval_generator = DataGenerator(\n    val_idx, shrink2=RED, batch_size=BATCH_SIZE\n)\n\nopt =keras.optimizers.Adam(learning_rate=0.001)# AdamAccumulate(lr=0.001, accum_iters=8)\nmodel2 = sm.Unet(\n    'efficientnetb2', \n    classes=4,\n    encoder_weights='imagenet',\n    decoder_filters = filters,\n    input_shape=(None, None, 3),\n    activation='sigmoid'\n)\nmodel2.compile(optimizer=opt, loss=jaccard_loss, metrics=[dice_coef])#,kaggle_dice,kaggle_acc])\n\ncheckpoint = cbs.ModelCheckpoint('model_'+str(1)+'.h5', save_best_only=True)\nes = cbs.EarlyStopping(monitor='val_dice_coef', min_delta=0.001, patience=7, verbose=1, mode='max')\nrlr = cbs.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=2, verbose=1, mode='max', min_delta=0.001)\n\nhistory = model2.fit_generator(\n     train_generator,\n     validation_data=val_generator,\n     callbacks=[rlr, es, checkpoint],\n     epochs=50,\n     verbose=1, workers=2\n)","execution_count":null,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n31940608/31936256 [==============================] - 1s 0us/step\nEpoch 1/50\n312/312 [==============================] - 331s 1s/step - loss: 0.6713 - dice_coef: 0.4821 - val_loss: 0.6733 - val_dice_coef: 0.4919\nEpoch 2/50\n312/312 [==============================] - 326s 1s/step - loss: 0.6089 - dice_coef: 0.5577 - val_loss: 0.6162 - val_dice_coef: 0.5468\nEpoch 3/50\n312/312 [==============================] - 324s 1s/step - loss: 0.5993 - dice_coef: 0.5681 - val_loss: 0.6826 - val_dice_coef: 0.4988\nEpoch 4/50\n312/312 [==============================] - ETA: 0s - loss: 0.5898 - dice_coef: 0.5769\nEpoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n312/312 [==============================] - 324s 1s/step - loss: 0.5898 - dice_coef: 0.5769 - val_loss: 0.6465 - val_dice_coef: 0.5179\nEpoch 5/50\n312/312 [==============================] - 324s 1s/step - loss: 0.5760 - dice_coef: 0.5915 - val_loss: 0.5891 - val_dice_coef: 0.5931\nEpoch 6/50\n312/312 [==============================] - 325s 1s/step - loss: 0.5693 - dice_coef: 0.5984 - val_loss: 0.5832 - val_dice_coef: 0.5909\nEpoch 7/50\n312/312 [==============================] - 321s 1s/step - loss: 0.5677 - dice_coef: 0.5989 - val_loss: 0.5731 - val_dice_coef: 0.5999\nEpoch 8/50\n312/312 [==============================] - 324s 1s/step - loss: 0.5657 - dice_coef: 0.6015 - val_loss: 0.5785 - val_dice_coef: 0.5958\nEpoch 9/50\n312/312 [==============================] - ETA: 0s - loss: 0.5653 - dice_coef: 0.6024\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n312/312 [==============================] - 318s 1s/step - loss: 0.5653 - dice_coef: 0.6024 - val_loss: 0.5764 - val_dice_coef: 0.5928\nEpoch 10/50\n312/312 [==============================] - 324s 1s/step - loss: 0.5560 - dice_coef: 0.6110 - val_loss: 0.5585 - val_dice_coef: 0.6188\nEpoch 11/50\n312/312 [==============================] - 324s 1s/step - loss: 0.5547 - dice_coef: 0.6122 - val_loss: 0.5632 - val_dice_coef: 0.6156\nEpoch 12/50\n312/312 [==============================] - ETA: 0s - loss: 0.5555 - dice_coef: 0.6125\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n312/312 [==============================] - 326s 1s/step - loss: 0.5555 - dice_coef: 0.6125 - val_loss: 0.5582 - val_dice_coef: 0.6179\nEpoch 13/50\n 88/312 [=======>......................] - ETA: 3:42 - loss: 0.5503 - dice_coef: 0.6185","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\n\nmodel1 = sm.Unet(\n    'efficientnetb1', \n    classes=4,\n    encoder_weights='imagenet',\n    decoder_filters = filters,\n    input_shape=(None, None, 3),\n    activation='sigmoid'\n)\nmodel2.compile(optimizer=opt, loss=jaccard_loss, metrics=[dice_coef])#,kaggle_dice,kaggle_acc])\n\ncheckpoint = cbs.ModelCheckpoint('model_'+str(2)+'.h5', save_best_only=True)\nes = cbs.EarlyStopping(monitor='val_dice_coef', min_delta=0.001, patience=7, verbose=1, mode='max')\nrlr = cbs.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=2, verbose=1, mode='max', min_delta=0.001)\n\nhistory = model2.fit_generator(\n     train_generator,\n     validation_data=val_generator,\n     callbacks=[rlr, es, checkpoint],\n     epochs=50,\n     verbose=1, workers=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 10\n\n\ntrain_generator = DataGenerator(\n    train_idx, flips=True, augment=True, shuffle=True, shrink2=RED, batch_size=BATCH_SIZE,\n)\n\nval_generator = DataGenerator(\n    val_idx, shrink2=RED, batch_size=BATCH_SIZE\n)\n\nmodel3 = sm.Unet(\n    'efficientnetb3', \n    classes=4,\n    encoder_weights='imagenet',\n    decoder_filters = filters,\n    input_shape=(None, None, 3),\n    activation='sigmoid'\n)\nmodel3.compile(optimizer=opt, loss=jaccard_loss, metrics=[dice_coef])#,kaggle_dice,kaggle_acc])\n\ncheckpoint = cbs.ModelCheckpoint('model_'+str(3)+'.h5', save_best_only=True)\nes = cbs.EarlyStopping(monitor='val_dice_coef', min_delta=0.001, patience=7, verbose=1, mode='max')\nrlr = cbs.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=2, verbose=1, mode='max', min_delta=0.001)\n\nhistory = model3.fit_generator(\n     train_generator,\n     validation_data=val_generator,\n     callbacks=[rlr, es, checkpoint],\n     epochs=50,\n     verbose=1, workers=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 10\n\n\nmodel4 = sm.Unet(\n    'efficientnetb4', \n    classes=4,\n    encoder_weights='imagenet',\n    decoder_filters = filters,\n    input_shape=(None, None, 3),\n    activation='sigmoid'\n)\nmodel2.compile(optimizer=opt, loss=jaccard_loss, metrics=[dice_coef])#,kaggle_dice,kaggle_acc])\n\ncheckpoint = cbs.ModelCheckpoint('model_'+str(4)+'.h5', save_best_only=True)\nes = cbs.EarlyStopping(monitor='val_dice_coef', min_delta=0.001, patience=7, verbose=1, mode='max')\nrlr = cbs.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=2, verbose=1, mode='max', min_delta=0.001)\n\nhistory = model2.fit_generator(\n     train_generator,\n     validation_data=val_generator,\n     callbacks=[rlr, es, checkpoint],\n     epochs=50,\n     verbose=1, workers=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/understanding_cloud_organization/sample_submission.csv')\nsub['Image'] = sub['Image_Label'].map(lambda x: x.split('.')[0])\nsub['Label'] = sub['Image_Label'].map(lambda x: x.split('_')[1])\n# LOAD TEST CLASSIFIER PREDICTIONS\nsub['p'] = pd.read_csv('../input/cloud-classifiers/pred_cls.csv').p.values\nsub['p'] += np.load('../input/cloud-classifiers/pred_cls0.npy').reshape((-1)) * 0.5\nsub['p'] += pd.read_csv('../input/cloud-classifiers/pred_cls3.csv').p.values * 3.0\nsub['p'] += np.load('/kaggle/input/cloud-classifiers/pred_cls4b.npy') * 0.6\nsub['p'] /= 5.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"USE_TTA=True\nDO_TEST=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Computing masks for',len(sub)//4,'test images with 3 models'); sub.EncodedPixels = ''\nPTH = '../input/cloud-images-resized/test_images_384x576/'; bs = 4\nif USE_TTA: bs=1\ntest_gen = DataGenerator(sub.Image[::4].values+'.jpg', width=576, height=384, batch_size=bs, mode='predict',path=PTH)\n\nsz = 20000.*(576/525)*(384/350)/RED/RED\n\npixt = [0.5,0.5,0.5,0.35] #; pixt = [0.4,0.4,0.4,0.4]\nszt = [25000., 20000., 22500., 15000.] #; szt = [20000., 20000., 20000., 20000.]\nfor k in range(len(szt)): szt[k] = szt[k]*(576./525.)*(384./350.)/RED/RED\n\nif DO_TEST:\n    for b,batch in enumerate(test_gen):\n        btc = model1.predict_on_batch(batch)\n        btc += model2.predict_on_batch(batch)\n        btc += model3.predict_on_batch(batch)\n        btc += model4.predict_on_batch(batch)\n        btc /= 4.0\n\n        for j in range(btc.shape[0]):\n            for i in range(btc.shape[-1]):\n                mask = (btc[j,:,:,i]>pixt[i]).astype(int); rle = ''\n                if np.sum(mask)>szt[i]: rle = mask2rleXXX( mask ,shape=(576//RED,384//RED))\n                sub.iloc[4*(bs*b+j)+i,1] = rle\n        if b%(100//bs)==0: print(b*bs,', ',end='')\n#         t = np.round( (time.time() - kernel_start)/60,1 )\n#         if t > LIMIT*60:\n#             print('#### EXCEEDED TIME LIMIT. STOPPING NOW ####')\n#             break\n\n    sub[['Image_Label','EncodedPixels']].to_csv('sub_seg.csv',index=False)\n    sub.loc[(sub.p<0.5)&(sub.Label=='Fish'),'EncodedPixels'] = ''\n    sub.loc[(sub.p<0.3)&(sub.Label=='Flower'),'EncodedPixels'] = ''\n    sub.loc[(sub.p<0.5)&(sub.Label=='Gravel'),'EncodedPixels'] = ''\n    sub.loc[(sub.p<0.5)&(sub.Label=='Sugar'),'EncodedPixels'] = ''\n    sub[['Image_Label','EncodedPixels']].to_csv('submission.csv',index=False)\n\nsub.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}